{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "tTMbMovcwrJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_l77VDPwFMn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "def read_file_in_chunks_return_head(file_path, sep='\\t', compression='bz2', chunksize=1000):\n",
        "    try:\n",
        "        chunk_iter = pd.read_csv(file_path, sep=sep, compression=compression, chunksize=chunksize)\n",
        "        first_chunk = next(chunk_iter)\n",
        "        for chunk in chunk_iter:\n",
        "            # check the data in each chunk\n",
        "            print(chunk.head())\n",
        "        print(f\"File {file_path} read successfully in chunks\")\n",
        "        return first_chunk.head(2)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "\n",
        "audio_features_mfcc_head = read_file_in_chunks_return_head('./audio_features/id_compare_mfcc_stats.tsv.bz2')\n",
        "print(\"succeed!\")\n",
        "print(\"Audio Features - MFCC (head):\")\n",
        "print(audio_features_mfcc_head)\n",
        "\n",
        "print(\"\\nFinish read all files head. \")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def process_chunk(chunk, all_chunks):\n",
        "    # process data in each chunk\n",
        "    all_chunks.append(chunk)\n",
        "    print(f\"Processed chunk of size: {chunk.shape}\")\n",
        "\n",
        "def read_file_in_chunks(file_path, sep='\\t', compression='bz2', chunksize=10000):\n",
        "    try:\n",
        "        chunk_iter = pd.read_csv(file_path, sep=sep, compression=compression, chunksize=chunksize)\n",
        "        all_chunks = []\n",
        "        for chunk in chunk_iter:\n",
        "            process_chunk(chunk, all_chunks)\n",
        "        data = pd.concat(all_chunks, ignore_index=True)\n",
        "        print(f\"File {file_path} read successfully in chunks\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "0Waw80kTwzge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features_mfcc = read_file_in_chunks('./audio_features/id_compare_mfcc_stats.tsv.bz2')\n",
        "print(\"Finish reading audio features!\")\n",
        "\n",
        "lyrics_vad_bow = read_file_in_chunks('./id_vad_bow.tsv.bz2')\n",
        "print(\"Finish reading lyrice vad_bow features sentiment!\")"
      ],
      "metadata": {
        "id": "qThLbefuyGES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_by_id(df):\n",
        "    \"\"\"\n",
        "    sort dataframe based on 'id'\n",
        "    \"\"\"\n",
        "    sorted_df = df.sort_values(by='id').reset_index(drop=True)\n",
        "    return sorted_df\n",
        "\n",
        "audio_features_mfcc = sort_by_id(audio_features_mfcc)\n",
        "print(audio_features_mfcc.head())\n",
        "\n",
        "lyrics_vad_bow = sort_by_id(lyrics_vad_bow)\n",
        "print(lyrics_vad_bow.head())\n"
      ],
      "metadata": {
        "id": "RPKNy8Okw759"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "select data"
      ],
      "metadata": {
        "id": "0Ido7RLXxF8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_chunks(data, chunk_size, extraction_size):\n",
        "    chunks = []\n",
        "    for i in range(0, len(data), chunk_size):\n",
        "        chunk = data[i:i+chunk_size]\n",
        "        extracted_chunk = chunk.head(extraction_size)\n",
        "        chunks.append(extracted_chunk)\n",
        "        print(f\"Extracted chunk {i // chunk_size + 1}: {extracted_chunk.shape}\")\n",
        "    return pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "\n",
        "chunk_size = 1000\n",
        "extraction_size = 4\n",
        "audio_chunks = extract_chunks(audio_features_mfcc, chunk_size, extraction_size)\n",
        "audio_chunks.to_csv('./audio_features/extracted_audio_features.tsv.bz2', sep='\\t', index=False, compression='bz2')\n",
        "print(\"Extraction and saving completed.\")\n",
        "\n",
        "\n",
        "lyrics_chunks_vad_bow = extract_chunks(lyrics_vad_bow, chunk_size, extraction_size)\n",
        "lyrics_chunks_vad_bow.to_csv('./extracted_lyrics_vad_bow.tsv.bz2', sep='\\t', index=False, compression='bz2')\n",
        "print(\"Extraction and saving completed.\")"
      ],
      "metadata": {
        "id": "aVrEWTsGxFpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data cleaning"
      ],
      "metadata": {
        "id": "vRv1OYtaxjZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_chunk(chunk, chunk_type, all_chunks):\n",
        "    # chack and delete missing value\n",
        "    chunk = chunk.dropna()\n",
        "    # delete duplicates\n",
        "    chunk = chunk.drop_duplicates()\n",
        "    print(f\"Processed {chunk_type} chunk of size: {chunk.shape}\")\n",
        "    all_chunks.append(chunk)\n",
        "\n",
        "def read_and_process_chunks(file_path, chunk_type, sep=',', compression='gzip', chunksize=10000):\n",
        "    try:\n",
        "        chunk_iter = pd.read_csv(file_path, sep=sep, compression=compression, chunksize=chunksize)\n",
        "        all_chunks = []\n",
        "        for chunk in chunk_iter:\n",
        "            process_chunk(chunk, chunk_type, all_chunks)\n",
        "        data = pd.concat(all_chunks, ignore_index=True)\n",
        "        print(f\"File {file_path} read and processed successfully in chunks\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 分块读取和处理数据\n",
        "audio_features = read_and_process_chunks('./audio_features/extracted_audio_features.csv.gz', 'audio')\n",
        "lyrics_vad_bow_features = read_and_process_chunks('./extracted_lyrics_vad_bow_features.csv.gz', 'lyrics')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9s0gXv3rxjF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "common_ids = set(audio_features['id']).intersection(set(lyrics_vad_bow_features['id']))\n",
        "audio_features = audio_features[audio_features['id'].isin(common_ids)]\n",
        "lyrics_vad_bow_features = lyrics_vad_bow_features[lyrics_vad_bow_features['id'].isin(common_ids)]\n",
        "\n",
        "audio_features = audio_features.drop_duplicates(subset=['id'])\n",
        "lyrics_vad_bow_features = lyrics_vad_bow_features.drop_duplicates(subset=['id'])\n",
        "\n",
        "# save cleaned data\n",
        "lyrics_sentiment_features.to_csv('./cleaned_lyrics_sentiment_features.csv.gz', sep=',', index=False, compression='gzip')\n",
        "lyrics_vad_bow_features.to_csv('./cleaned_lyrics_vad_bow_features.csv.gz', sep=',', index=False, compression='gzip')\n",
        "print(\"Data cleaning and saving completed.\")"
      ],
      "metadata": {
        "id": "_hQ8kePxyeHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data standardization"
      ],
      "metadata": {
        "id": "9kwUhL0Iy_CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def standardize_features(input_path, output_path, compression='gzip'):\n",
        "    df = pd.read_csv(input_path, compression=compression)\n",
        "    feature_columns = df.columns.difference(['id'])\n",
        "    # initial StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
        "    df.to_csv(output_path, index=False, compression=compression)\n",
        "    print(f\"Standardized features from {input_path} and saved to {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "audio_input_path = './cleaned_lyrics_sentiment_features.csv.gz'\n",
        "lyrics_input_path = './cleaned_lyrics_vad_bow_features.csv.gz'\n",
        "\n",
        "audio_output_path = './audio_features/standardized_audio_features.csv.gz'\n",
        "lyrics_output_path = './lyrice_features/standardized_lyrics_features.csv.gz'\n",
        "\n",
        "standardize_features(audio_input_path, audio_output_path)\n",
        "standardize_features(lyrics_input_path, lyrics_output_path)"
      ],
      "metadata": {
        "id": "8WQAoxTCzNbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA"
      ],
      "metadata": {
        "id": "74j8i59izmdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def determine_n_components(input_path, compression='gzip'):\n",
        "    df = pd.read_csv(input_path, compression=compression)\n",
        "    feature_columns = df.columns.difference(['id'])\n",
        "    pca = PCA()\n",
        "    pca.fit(df[feature_columns])\n",
        "    # calculate cumulative variance\n",
        "    cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    print(f\"Cumulative explained variance for {input_path}:\")\n",
        "    for i, variance in enumerate(cumulative_variance):\n",
        "        print(f\"PC{i+1}: {variance}\")\n",
        "        if variance >= 0.95:\n",
        "            print(f\"Selected number of components for {input_path}: {i+1}\")\n",
        "            return i+1\n",
        "\n",
        "audio_input_path = './audio_features/standardized_audio_features.csv.gz'\n",
        "lyrics_input_path = './lyrice_features/standardized_lyrics_features.csv.gz'\n",
        "\n",
        "# print the dimension number\n",
        "n_components_audio5 = determine_n_components(audio_input_path)\n",
        "n_components_lyrics5 = determine_n_components(lyrics_input_path)\n",
        "print(f\"Number of components selected for audio features: {n_components_audio5}\")\n",
        "print(f\"Number of components selected for lyrics features: {n_components_lyrics5}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MapmajFJzocF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply PCA\n",
        "def apply_pca(input_path, output_path, n_components, compression='gzip'):\n",
        "    df = pd.read_csv(input_path, compression=compression)\n",
        "    feature_columns = df.columns.difference(['id'])\n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca_features = pca.fit_transform(df[feature_columns])\n",
        "\n",
        "    pca_df = pd.DataFrame(pca_features, columns=[f'PC{i+1}' for i in range(n_components)])\n",
        "    pca_df.insert(0, 'id', df['id'])\n",
        "    pca_df.to_csv(output_path, index=False, compression=compression)\n",
        "    print(f\"Applied PCA on {input_path}, saved to {output_path}, explained variance ratio: {pca.explained_variance_ratio_.sum()}\")\n",
        "\n",
        "\n",
        "audio_output_path = './audio_features/pca_audio_features.csv.gz'\n",
        "lyrics_output_path = './lyrice_features/pca_lyrics_features.csv.gz'\n",
        "\n",
        "\n",
        "apply_pca(audio_input_path, audio_output_path, n_components=n_components_audio5)\n",
        "print(\"finish!\")\n",
        "apply_pca(lyrics_input_path, lyrics_output_path, n_components=n_components_lyrics5)\n",
        "print(\"finish!\")\n"
      ],
      "metadata": {
        "id": "niK6-fl8z5tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merge audio and lyrics features into multimodal features"
      ],
      "metadata": {
        "id": "NwE-Tbit1tpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pca_audio_features = pca_audio_features.drop(columns=['segment_id'], errors='ignore')\n",
        "pca_vad_bow_features = pca_vad_bow_features.drop(columns=['segment_id'], errors='ignore')\n",
        "\n",
        "multimodal_features = pd.merge(pca_audio_features, pca_vad_bow_features, on='id')\n",
        "\n",
        "print(\"Columns in multimodal_features after merging:\", multimodal_features.columns.tolist())\n",
        "print(f\"Shape of multimodal_features: {multimodal_features.shape}\")\n",
        "\n",
        "multimodal_features.to_csv('./multimodal_features.csv.gz', index=False, compression='gzip')"
      ],
      "metadata": {
        "id": "fUA2natR0Dvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "process metadata and transfer valences into emotion tags\n"
      ],
      "metadata": {
        "id": "8km6WY1fFyVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def process_chunk(chunk, all_chunks):\n",
        "    all_chunks.append(chunk)\n",
        "    print(f\"Processed chunk of size: {chunk.shape}\")\n",
        "\n",
        "def read_file_in_chunks(file_path, sep='\\t', chunksize=10000):\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        chunk_iter = pd.read_csv(file_path, sep=sep, chunksize=chunksize)\n",
        "        all_chunks = []\n",
        "        for chunk in chunk_iter:\n",
        "            process_chunk(chunk, all_chunks)\n",
        "        data = pd.concat(all_chunks, ignore_index=True)\n",
        "        end_time = time.time()\n",
        "        print(f\"File {file_path} read successfully in chunks. Total time: {end_time - start_time:.2f} seconds\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "metadata = read_file_in_chunks('./id_metadata.csv')\n",
        "print(\"Finish reading lyrice features!\")\n",
        "print(metadata.shape)\n"
      ],
      "metadata": {
        "id": "K9XYGqzgFqT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_by_id(df):\n",
        "    \"\"\"\n",
        "    sort the dataframe based on 'id' column\n",
        "    \"\"\"\n",
        "    sorted_df = df.sort_values(by='id').reset_index(drop=True)\n",
        "    return sorted_df\n",
        "\n",
        "metadata = sort_by_id(metadata)\n",
        "print(metadata.head())\n",
        "\n",
        "chunk_size = 1000\n",
        "extraction_size = 4\n",
        "\n",
        "metadata_chunks = extract_chunks(metadata, chunk_size, extraction_size)\n",
        "metadata_chunks.to_csv('./metadata.csv', sep='\\t', index=False, compression='bz2')\n",
        "print(\"Extraction and saving completed.\")\n",
        "metadata_chunks.to_csv('metadata.csv.gz', index=False, compression='gzip')\n"
      ],
      "metadata": {
        "id": "DvzhQPofF_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read features files\n",
        "pca_audio_features = pd.read_csv('./pca_audio_features.csv.gz', compression='gzip')\n",
        "pca_vad_bow_features = pd.read_csv('./pca_vad_bow_features.csv.gz', compression='gzip')\n",
        "multimodal_features = pd.read_csv('./multimodal_features.csv.gz', compression='gzip')\n",
        "\n",
        "\n",
        "audio_ids = set(pca_audio_features['id'])\n",
        "metadata_filtered = pd.DataFrame()\n",
        "\n",
        "#read meta data\n",
        "chunksize = 10000\n",
        "for chunk in pd.read_csv('./metadata.csv.gz', compression='gzip', chunksize=chunksize):\n",
        "    chunk_filtered = chunk[chunk['id'].isin(audio_ids)]\n",
        "    metadata_filtered = pd.concat([metadata_filtered, chunk_filtered], ignore_index=True)\n",
        "\n",
        "# only retain 'id' and 'valence' column\n",
        "metadata_filtered = metadata_filtered[['id', 'valence']]\n",
        "\n",
        "# function which merge valence column and add emotion column\n",
        "def add_emotion_column(features_df, metadata_df):\n",
        "    features_df = features_df.merge(metadata_df, on='id', how='inner')\n",
        "    features_df['emotion'] = features_df['valence'].apply(lambda x: 'negative' if x < 0.5 else 'positive')\n",
        "    features_df = features_df.drop(columns=['valence'])\n",
        "    return features_df\n",
        "\n",
        "# add 'emotion' column in three datasets\n",
        "pca_audio_features = add_emotion_column(pca_audio_features, metadata_filtered)\n",
        "pca_vad_bow_features = add_emotion_column(pca_vad_bow_features, metadata_filtered)\n",
        "multimodal_features = add_emotion_column(multimodal_features, metadata_filtered)\n",
        "\n",
        "\n",
        "pca_audio_features.to_csv('./pca_audio_features_with_emotion.csv.gz', index=False, compression='gzip')\n",
        "pca_vad_bow_features.to_csv('./pca_vad_bow_features_with_emotion.csv.gz', index=False, compression='gzip')\n",
        "multimodal_features.to_csv('./multimodal_features_with_emotion.csv.gz', index=False, compression='gzip')\n",
        "\n",
        "\n",
        "print(f\"Shape of pca_audio_features_with_emotion: {pca_audio_features.shape}\")\n",
        "print(pca_audio_features.head())\n",
        "print(f\"Shape of pca_vad_bow_features_with_emotion: {pca_vad_bow_features.shape}\")\n",
        "print(pca_vad_bow_features.head())\n",
        "print(f\"Shape of multimodal_features_with_emotion: {multimodal_features.shape}\")\n",
        "print(multimodal_features.head())\n"
      ],
      "metadata": {
        "id": "NqnRTpS3GE24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into training data and testing data"
      ],
      "metadata": {
        "id": "L8G6f4JB2URU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "pca_audio_features = pd.read_csv('./pca_audio_features_with_emotion.csv.gz', compression='gzip')\n",
        "pca_vad_bow_features = pd.read_csv('./pca_vad_bow_features_with_emotion.csv.gz', compression='gzip')\n",
        "pca_muitlmodal_features = pd.read_csv('./multimodal_features_with_emotion.csv.gz', compression='gzip')\n",
        "\n",
        "\n",
        "# target column 'emotion'\n",
        "target_column = 'emotion'\n",
        "\n",
        "# split dataset into training data and test data\n",
        "X_audio = pca_audio_features.drop(columns=[target_column, 'id'])\n",
        "y_audio = pca_audio_features[target_column]\n",
        "X_train_audio, X_test_audio, y_train_audio, y_test_audio = train_test_split(X_audio, y_audio, test_size=0.2, random_state=42)\n",
        "\n",
        "X_lyrics = pca_vad_bow_features.drop(columns=[target_column, 'id'])\n",
        "y_lyrics = pca_vad_bow_features[target_column]\n",
        "X_train_lyrics, X_test_lyrics, y_train_lyrics, y_test_lyrics = train_test_split(X_lyrics, y_lyrics, test_size=0.2, random_state=42)\n",
        "\n",
        "X_multimodal = pca_muitlmodal_features.drop(columns=[target_column, 'id'])\n",
        "y_multimodal = pca_muitlmodal_features[target_column]\n",
        "X_train_multimodal, X_test_multimodal, y_train_multimodal, y_test_multimodal = train_test_split(X_multimodal, y_multimodal, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHQ59-l72bCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T0LS1iqRGx5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q1II9bJXGxxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline\n"
      ],
      "metadata": {
        "id": "FqQB8GiO9C0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# define a simple RandomForestClassifier\n",
        "model_audio = RandomForestClassifier(random_state=42)\n",
        "model_lyrics = RandomForestClassifier(random_state=42)\n",
        "model_multimodal = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# evaluate the model using cross-validation\n",
        "def evaluate_model(X, y, model):\n",
        "    print(f'Before cross-validation: X shape = {X.shape}')\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "    print(f'After cross-validation: X shape = {X.shape}')\n",
        "    print(f'Cross-validation scores: {scores}')\n",
        "    print(f'Mean cross-validation score: {scores.mean()}')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"Audio Features Model Evaluation:\")\n",
        "print(X_train_audio.shape)\n",
        "audio_accuracy = evaluate_model(X_train_audio, y_train_audio, model_audio)\n",
        "\n",
        "print(\"\\nLyrics Features Model Evaluation:\")\n",
        "lyrics_accuracy = evaluate_model(X_train_lyrics, y_train_lyrics, model_lyrics)\n",
        "\n",
        "print(\"\\nMultimodal Features Model Evaluation:\")\n",
        "multimodal_accuracy = evaluate_model(X_train_multimodal, y_train_multimodal, model_multimodal)\n",
        "\n",
        "print(f\"\\nBaseline Audio Model Accuracy: {audio_accuracy}\")\n",
        "print(f\"Baseline Lyrics Model Accuracy: {lyrics_accuracy}\")\n",
        "print(f\"Baseline Multimodal Model Accuracy: {multimodal_accuracy}\")\n"
      ],
      "metadata": {
        "id": "R945MVTVHGeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization"
      ],
      "metadata": {
        "id": "fBMH1fhs9fE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Categorical\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "\n",
        "\n",
        "# define parameters in the model\n",
        "param_distributions = {\n",
        "    'n_estimators': Integer(100, 200),\n",
        "    'max_depth': Categorical([None, 10, 20]),\n",
        "}\n",
        "\n",
        "# create BayesSearchCV object\n",
        "def tune_model_bayes(X_train, y_train):\n",
        "    bayes_search = BayesSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=42),\n",
        "        search_spaces=param_distributions,\n",
        "        n_iter=30,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "    print(X_train.shape)\n",
        "    return bayes_search.best_params_, bayes_search.best_score_"
      ],
      "metadata": {
        "id": "W7YnjWHvHbMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params_audio, best_score_audio = tune_model_bayes(X_train_audio, y_train_audio)\n",
        "print(\"finish\")\n",
        "print(f\"Best Params (Audio): {best_params_audio}\")\n",
        "print(f\"Best Score (Audio): {best_score_audio}\")\n",
        "\n",
        "best_params_lyrics, best_score_lyrics = tune_model_bayes(X_train_lyrics, y_train_lyrics)\n",
        "print(\"finish\")\n",
        "print(f\"Best Params (Lyrics): {best_params_lyrics}\")\n",
        "print(f\"Best Score (Lyrics): {best_score_lyrics}\")\n",
        "\n",
        "best_params_multimodal, best_score_multimodal = tune_model_bayes(X_train_multimodal, y_train_multimodal)\n",
        "print(\"finish\")\n",
        "print(f\"Best Params (Multimodal): {best_params_multimodal}\")\n",
        "print(f\"Best Score (Multimodal): {best_score_multimodal}\")\n"
      ],
      "metadata": {
        "id": "1sH56IyEHnz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model retraining and evaluation"
      ],
      "metadata": {
        "id": "fqG78jQsHvef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_audio_encoded = np.where(y_audio == 'positive', 1, 0)\n",
        "y_lyrics_encoded = np.where(y_lyrics == 'positive', 1, 0)\n",
        "y_multimodal_encoded = np.where(y_multimodal == 'positive', 1, 0)"
      ],
      "metadata": {
        "id": "A4SK1dXvJPvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# retrain model with best parameters\n",
        "def train_and_evaluate_model(X_train, y_train, X_test, y_test, best_params):\n",
        "    model = RandomForestClassifier(**best_params, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "BNfk7pN3JQrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat evaluation\n",
        "def repeated_train_test(X, y, best_params, n_repeats=6, test_size=0.3):\n",
        "    accuracies, precisions, recalls, f1s, roc_curves, conf_matrices = [], [], [], [], [], []\n",
        "    accuracies = []\n",
        "    for _ in range(n_repeats):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None)\n",
        "        accuracy = train_and_evaluate_model(X_train, y_train, X_test, y_test, best_params)\n",
        "        accuracies.append(accuracy)\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    return np.array(accuracies), mean_accuracy"
      ],
      "metadata": {
        "id": "n778lejBJQoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracies_audio, mean_accuracy = repeated_train_test(X_audio, y_audio_encoded, best_params_audio)\n",
        "print(f\"Test Accuracies (Audio): {accuracies_audio}\")\n",
        "print(f\"mean accuracy: {mean_accuracy}\")"
      ],
      "metadata": {
        "id": "01MaPsVjJQmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_lyrics, mean_accuracy = repeated_train_test(X_lyrics, y_lyrics_encoded, best_params_lyrics)\n",
        "print(f\"Test Accuracies (Lyrics): {accuracies_lyrics}\")\n",
        "print(f\"mean accuracy: {mean_accuracy}\")"
      ],
      "metadata": {
        "id": "zP7shpOQJQjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_multi, mean_accuracy = repeated_train_test(X_multimodal, y_multimodal_encoded, best_params_multimodal)\n",
        "print(f\"Test Accuracies (Multi): {accuracies_multi}\")\n",
        "print(f\"mean accuracy: {mean_accuracy}\")"
      ],
      "metadata": {
        "id": "h-ohGgjcHvSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hypothesis test"
      ],
      "metadata": {
        "id": "zEDcCY84JpSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test whether the data is normal distribution\n",
        "def check_normality(data):\n",
        "    stat, p_value = shapiro(data)\n",
        "    print('Shapiro-Wilk Test: stat=%.3f, p-value=%.3f' % (stat, p_value))\n",
        "    #stats.probplot(data, dist=\"norm\", plot=plt)\n",
        "    #plt.show()\n",
        "    return p_value > 0.05\n",
        "\n",
        "# choose proper statistic test method\n",
        "def perform_statistical_tests(data1, data2):\n",
        "    if check_normality(data1) and check_normality(data2):\n",
        "        t_stat, p_value = ttest_rel(data1, data2)\n",
        "\n",
        "        print('Paired t-test: t-statistic=%.3f, p-value=%.3f' % (t_stat, p_value))\n",
        "    else:\n",
        "        stat, p_value = wilcoxon(data1, data2)\n",
        "\n",
        "        print('Wilcoxon test: statistic=%.3f, p-value=%.3f' % (stat, p_value))"
      ],
      "metadata": {
        "id": "g4GoDxCZJxP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_statistical_tests(accuracies_multi, accuracies_audio)\n",
        "perform_statistical_tests(accuracies_multi, accuracies_lyrics)\n",
        "perform_statistical_tests(accuracies_audio, accuracies_lyrics)"
      ],
      "metadata": {
        "id": "Q9wf9hGEKJKd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
